{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "########## part a ##########\n",
    "categories = [\"comp.graphics\", \"comp.os.ms-windows.misc\", \"comp.sys.ibm.pc.hardware\",\n",
    "              \"comp.sys.mac.hardware\", \"rec.autos\", \"rec.motorcycles\", \"rec.sport.baseball\",\n",
    "              \"rec.sport.hockey\"]\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "count = collections.Counter(train.target)\n",
    "freqs = [count[i] for i in count]\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.bar(range(0,8), freqs)\n",
    "plt.xticks(range(0,8), train.target_names, rotation=90)\n",
    "plt.xlabel(\"categories\")\n",
    "plt.ylabel(\"freqs\")\n",
    "plt.ylim((0,650))\n",
    "plt.show()\n",
    "\n",
    "freqs_major = [sum(freqs[:4]), sum(freqs[4:])]\n",
    "class_major = [\"computer technology\", \"recreational activity\"]\n",
    "plt.bar(range(0,2), freqs_major)\n",
    "plt.xticks(range(0,2), class_major, rotation=90)\n",
    "plt.xlabel(\"categories\")\n",
    "plt.ylabel(\"freqs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## part b ##########\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# preprocess train data\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.snowball = SnowballStemmer(\"english\")\n",
    "    def __call__(self, data):\n",
    "        data = re.sub('[,.-:/()?{}*$#&]',' ', data)\n",
    "        data = ''.join(c for c in data if c not in string.punctuation)\n",
    "        data = ''.join(c for c in data if ord(c)<128)\n",
    "        data = data.lower()\n",
    "        data = data.split()\n",
    "        stop_words = text.ENGLISH_STOP_WORDS\n",
    "        clean_data = [w for w in data if w not in stop_words]\n",
    "\n",
    "        return [self.snowball.stem(w) for w in clean_data]\n",
    "\n",
    "vectorizer_2 = CountVectorizer(tokenizer=Tokenizer(), lowercase=True, min_df=2)\n",
    "tfidf_2 = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "pipeline_2 = Pipeline([('vectorizer_2', vectorizer_2), ('tfidf_2', tfidf_2)])\n",
    "train_idf_2 = pipeline_2.fit_transform(train.data)\n",
    "print (train_idf_2.shape)\n",
    "print (\"number of documents: \", train_idf_2.shape[0])\n",
    "print (\"number of terms in tfidf representation: \", train_idf_2.shape[1])\n",
    "\n",
    "vectorizer_5 = CountVectorizer(tokenizer=Tokenizer(), lowercase=True, min_df=5)\n",
    "tfidf_5 = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "pipeline_5 = Pipeline([('vectorizer_5', vectorizer_5), ('tfidf_5', tfidf_5)])\n",
    "train_idf_5 = pipeline_5.fit_transform(train.data)\n",
    "print (train_idf_5.shape)\n",
    "print (\"number of documents: \", train_idf_5.shape[0])\n",
    "print (\"number of terms in tfidf representation: \", train_idf_5.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## part b ##########\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# preprocess train data\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.snowball = SnowballStemmer(\"english\")\n",
    "    def __call__(self, data):\n",
    "        data = re.sub('[,.-:/()?{}*$#&]',' ', data)\n",
    "        data = ''.join(c for c in data if c not in string.punctuation)\n",
    "        data = ''.join(c for c in data if ord(c)<128)\n",
    "        data = data.lower()\n",
    "        data = data.split()\n",
    "        stop_words = text.ENGLISH_STOP_WORDS\n",
    "        clean_data = [w for w in data if w not in stop_words]\n",
    "\n",
    "        return [self.snowball.stem(w) for w in clean_data]\n",
    "\n",
    "vectorizer_2 = CountVectorizer(tokenizer=Tokenizer(), lowercase=True, min_df=2)\n",
    "tfidf_2 = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "pipeline_2 = Pipeline([('vectorizer_2', vectorizer_2), ('tfidf_2', tfidf_2)])\n",
    "train_idf_2 = pipeline_2.fit_transform(train.data)\n",
    "print (train_idf_2.shape)\n",
    "print (\"number of documents: \", train_idf_2.shape[0])\n",
    "print (\"number of terms in tfidf representation: \", train_idf_2.shape[1])\n",
    "\n",
    "vectorizer_5 = CountVectorizer(tokenizer=Tokenizer(), lowercase=True, min_df=5)\n",
    "tfidf_5 = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "pipeline_5 = Pipeline([('vectorizer_5', vectorizer_5), ('tfidf_5', tfidf_5)])\n",
    "train_idf_5 = pipeline_5.fit_transform(train.data)\n",
    "print (train_idf_5.shape)\n",
    "print (\"number of documents: \", train_idf_5.shape[0])\n",
    "print (\"number of terms in tfidf representation: \", train_idf_5.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "class_tficf = tfidf_transformer.fit_transform(class_counts)\n",
    "class_tficf_arr = class_tficf.toarray()\n",
    "\n",
    "keys=vocab_new.keys()\n",
    "map={}\n",
    "for i in range(len(keys)):\n",
    "    map[keys[i]] = class_tficf_arr[:,i]\n",
    "\n",
    "for i in [3,4,6,15]:\n",
    "    res = sorted(map.items(), key =lambda x:x[1][i])\n",
    "    res.reverse()\n",
    "    for j in range(10):\n",
    "        print res[j][0],\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## part d ##########\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "X_2 = TruncatedSVD(n_components=50)\n",
    "train_LSI_2 = X_2.fit_transform(train_idf_2)\n",
    "\n",
    "X_5 = TruncatedSVD(n_components=50)\n",
    "train_LSI_5 = X_5.fit_transform(train_idf_5)\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "Y_2 = NMF(n_components=50)\n",
    "train_NMF_2 = Y_2.fit_transform(train_idf_2)\n",
    "\n",
    "Y_5 = NMF(n_components=50)\n",
    "train_NMF_5 = Y_5.fit_transform(train_idf_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "class_names = ['Computer Tech', 'Recreation']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    print('Confusion matrix')\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e LSI-2#######\n",
    "categories = [\"comp.graphics\", \"comp.os.ms-windows.misc\", \"comp.sys.ibm.pc.hardware\",\n",
    "              \"comp.sys.mac.hardware\", \"rec.autos\", \"rec.motorcycles\", \"rec.sport.baseball\",\n",
    "              \"rec.sport.hockey\"]\n",
    "\n",
    "train_targets = []\n",
    "for i in train.target:\n",
    "    if i >= 4:\n",
    "        train_targets.append(1)\n",
    "    else:\n",
    "        train_targets.append(0)\n",
    "test = fetch_20newsgroups(subset=\"test\", categories=categories, shuffle=True, random_state=42)\n",
    "test_targets = []\n",
    "for i in test.target:\n",
    "    if i >= 4:\n",
    "        test_targets.append(1)\n",
    "    else:\n",
    "        test_targets.append(0)\n",
    "       \n",
    "hard_classifier = svm.LinearSVC(C=1000 ,dual=False, random_state=42)   \n",
    "hard_classifier.fit(train_LSI_2, train_targets)\n",
    "\n",
    "test_idf_2 = pipeline_2.transform(test.data)\n",
    "test_LSI = X_2.transform(test_idf_2)\n",
    "      \n",
    "predicted = hard_classifier.predict(test_LSI)\n",
    "\n",
    "score = hard_classifier.decision_function(test_LSI)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "\n",
    "print(\"Accuracy of Hard Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Hard Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e-1 LSI-5#######\n",
    "hard_classifier = svm.LinearSVC(C=1000 ,dual=False, random_state=42)     \n",
    "hard_classifier.fit(train_LSI_5, train_targets)\n",
    "\n",
    "test_idf_5 = pipeline_5.transform(test.data)\n",
    "test_LSI = X_5.transform(test_idf_5)\n",
    "     \n",
    "predicted = hard_classifier.predict(test_LSI)\n",
    "\n",
    "score = hard_classifier.decision_function(test_LSI)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "\n",
    "print(\"Accuracy of Hard Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Hard Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e-1 NMF#######    \n",
    "hard_classifier = svm.LinearSVC(C=1000 ,dual=False, random_state=42)     \n",
    "hard_classifier.fit(train_NMF_2, train_targets)\n",
    "\n",
    "test_idf_2 = pipeline_2.transform(test.data)\n",
    "test_NMF = Y_2.transform(test_idf_2)\n",
    "     \n",
    "predicted = hard_classifier.predict(test_NMF)\n",
    "\n",
    "score = hard_classifier.decision_function(test_NMF)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "# Report results\n",
    "print(\"Accuracy of Hard Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Hard Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e-2 L-2#######\n",
    "soft_classifier = svm.LinearSVC(C=0.001 ,dual=False, random_state=42)      \n",
    "soft_classifier.fit(train_LSI_2, train_targets)\n",
    "\n",
    "test_LSI = X_2.transform(test_idf_2)\n",
    "     \n",
    "predicted = soft_classifier.predict(test_LSI)\n",
    "\n",
    "score = soft_classifier.decision_function(test_LSI)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "print(\"Accuracy of Soft Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Soft Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e-2 L-5#######\n",
    "soft_classifier = svm.LinearSVC(C=0.001 ,dual=False, random_state=42)  \n",
    "soft_classifier.fit(train_LSI_5, train_targets)\n",
    "\n",
    "test_LSI = X_5.transform(test_idf_5)        \n",
    "predicted = soft_classifier.predict(test_LSI)\n",
    "\n",
    "score = soft_classifier.decision_function(test_LSI)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "\n",
    "print(\"Accuracy of Soft Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Soft Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### part e-2 NMF#######\n",
    "soft_classifier = svm.LinearSVC(C=0.001 ,dual=False, random_state=42)\n",
    "soft_classifier.fit(train_NMF_2, train_targets)\n",
    "\n",
    "test_NMF = Y_2.transform(test_idf_2)\n",
    "    \n",
    "predicted = soft_classifier.predict(test_NMF)\n",
    "\n",
    "score = soft_classifier.decision_function(test_NMF)\n",
    "accuracy = np.mean(predicted == test_targets)\n",
    "\n",
    "print(\"Accuracy of Soft Margin SVM: \" + str(accuracy))\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(test_targets, predicted, target_names=['Computer technology', 'Recreational activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(test_targets, score)\n",
    "line = [0, 1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "plt.title('ROC-Curve of Soft Margin SVM Classification', fontsize = 20)\n",
    "plt.axis([-0.004, 1, 0, 1.006])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 fold \n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(train_targets), n_folds=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#built 5*7 SVM classifier FOR LSI-2\n",
    "matrix = [[0]*7 for i in range(5)]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train_LSI_2[train_index], train_LSI_2[test_index]\n",
    "    for k in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "        X_train_target_group = [ int(x / 4) for x in train.target[train_index]]\n",
    "        X_test_target_group = [ int(x / 4) for x in train.target[test_index]]\n",
    "        \n",
    "        soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "        soft_svm_clf.fit(X_train, X_train_target_group)\n",
    "        score = soft_svm_clf.score(X_test, X_test_target_group)\n",
    "        matrix[i][j]=score\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n",
    "    \n",
    "avg_value = np.array(matrix)\n",
    "\n",
    "max = 0\n",
    "max_index = 0\n",
    "for i in range (7):\n",
    "    mean = np.mean(avg_value[:,i:i+1])\n",
    "    if max < mean:\n",
    "        max = mean\n",
    "        max_index = i\n",
    "print (max, max_index)\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best penalty value is',10**penalty[max_index])\n",
    "\n",
    "\n",
    "soft_svc = svm.LinearSVC(C=10**-2)\n",
    "soft_svc.fit(train_LSI_2, train_targets)\n",
    "soft_svc_predicted = soft_svc.predict(test_LSI)\n",
    "score = soft_svc.score(test_LSI, test_targets)\n",
    "print (score)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, soft_svc_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "soft_svc_accuracy = accuracy_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_accuracy)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "soft_svc_precision_score = precision_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "soft_svc_recall_score = recall_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#built 5*7 SVM classifier FOR LSI-5\n",
    "matrix = [[0]*7 for i in range(5)]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train_LSI_5[train_index], train_LSI_5[test_index]\n",
    "    for k in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "        X_train_target_group = [ int(x / 4) for x in train.target[train_index]]\n",
    "        X_test_target_group = [ int(x / 4) for x in train.target[test_index]]\n",
    "        \n",
    "        soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "        soft_svm_clf.fit(X_train, X_train_target_group)\n",
    "        score = soft_svm_clf.score(X_test, X_test_target_group)\n",
    "        matrix[i][j]=score\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n",
    "    \n",
    "avg_value = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max = 0\n",
    "max_index = 0\n",
    "for i in range (7):\n",
    "    mean = np.mean(avg_value[:,i:i+1])\n",
    "    if max < mean:\n",
    "        max = mean\n",
    "        max_index = i\n",
    "print (max, max_index)\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best penalty value is',10**penalty[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soft_svc = svm.LinearSVC(C=10**-2)\n",
    "soft_svc.fit(train_LSI_5, train_targets)\n",
    "soft_svc_predicted = soft_svc.predict(test_LSI)\n",
    "score = soft_svc.score(test_LSI, test_targets)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, soft_svc_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "soft_svc_accuracy = accuracy_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_accuracy)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "soft_svc_precision_score = precision_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "soft_svc_recall_score = recall_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###5-fold with NMF ###\n",
    "\n",
    "matrix = [[0]*7 for i in range(5)]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train_NMF_2[train_index], train_NMF_2[test_index]\n",
    "    for k in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "        X_train_target_group = [ int(x / 4) for x in train.target[train_index]]\n",
    "        X_test_target_group = [ int(x / 4) for x in train.target[test_index]]\n",
    "        soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "        soft_svm_clf.fit(X_train, X_train_target_group)\n",
    "        score = soft_svm_clf.score(X_test, X_test_target_group)\n",
    "        matrix[i][j]=score\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n",
    "    \n",
    "avg_value = np.array(matrix)\n",
    "\n",
    "max = 0\n",
    "max_index = 0\n",
    "for i in range (7):\n",
    "    mean = np.mean(avg_value[:,i:i+1])\n",
    "    if max < mean:\n",
    "        max = mean\n",
    "        max_index = i\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best penalty value is',10**penalty[max_index])\n",
    "\n",
    "soft_svc = svm.LinearSVC(C=10**-2)\n",
    "soft_svc.fit(train_NMF_2, train_targets)\n",
    "soft_svc_predicted = soft_svc.predict(test_NMF)\n",
    "score = soft_svc.score(test_NMF, test_targets)\n",
    "print (score)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, soft_svc_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "soft_svc_accuracy = accuracy_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_accuracy)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "soft_svc_precision_score = precision_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_precision_score)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "soft_svc_recall_score = recall_score(test_targets, soft_svc_predicted)\n",
    "print (soft_svc_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import auc\n",
    "# nb_clf = GaussianNB()\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(train_NMF_2, train_targets)\n",
    "nb_predicted = nb_clf.predict(test_NMF)\n",
    "\n",
    "y_score_test_nb = nb_clf.predict(test_NMF)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_nb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predicted = nb_clf.predict(test_NMF)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, nb_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_targets, nb_predicted)\n",
    "print (nb_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_targets, nb_predicted)\n",
    "print (nb_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_targets, nb_predicted)\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part f & i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for L-2  ###\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import linear_model, datasets\n",
    "lr_norm2 = linear_model.LogisticRegression()\n",
    "lr_norm2.fit(train_LSI_2, train_targets)\n",
    "y_score_test_lr_norm2 = lr_norm2.decision_function(test_LSI)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_norm2_predicted = lr_norm2.predict(test_LSI)\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm2_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr_norm2_accuracy = accuracy_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "lr_norm2_recall_score = recall_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "lr_norm2_precision_score = precision_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_precision_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "coef = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for c in coef:\n",
    "    lr_norm2 = linear_model.LogisticRegression(C = c)\n",
    "    lr_norm2.fit(train_LSI_2, train_targets)\n",
    "    lr_norm2_predicted = lr_norm2.predict(test_LSI)\n",
    "    y_score_test_lr_norm2 = lr_norm2.decision_function(test_LSI)\n",
    "    print (\"coef:\", c)\n",
    "    print (confusion_matrix(test_targets, lr_norm2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for LSI_5\n",
    "lr_norm2 = linear_model.LogisticRegression()\n",
    "lr_norm2.fit(train_LSI_5, train_targets)\n",
    "y_score_test_lr_norm2 = lr_norm2.decision_function(test_LSI)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "lr_norm2_predicted = lr_norm2.predict(test_LSI)\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm2_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_norm2_accuracy = accuracy_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "lr_norm2_recall_score = recall_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "lr_norm2_precision_score = precision_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_precision_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "coef = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for c in coef:\n",
    "    lr_norm2 = linear_model.LogisticRegression(C = c)\n",
    "    lr_norm2.fit(train_LSI_5, train_targets)\n",
    "    lr_norm2_predicted = lr_norm2.predict(test_LSI)\n",
    "    y_score_test_lr_norm2 = lr_norm2.decision_function(test_LSI)\n",
    "    print (\"coef:\", c)\n",
    "    print (confusion_matrix(test_targets, lr_norm2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### For NMF ###\n",
    "from sklearn import linear_model, datasets\n",
    "lr_norm2 = linear_model.LogisticRegression()\n",
    "lr_norm2.fit(train_NMF_2, train_targets)\n",
    "\n",
    "y_score_test_lr_norm2 = lr_norm2.decision_function(test_NMF)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "lr_norm2_predicted = lr_norm2.predict(test_NMF)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm2_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_norm2_accuracy = accuracy_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "lr_norm2_recall_score = recall_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "lr_norm2_precision_score = precision_score(test_targets, lr_norm2_predicted)\n",
    "print (lr_norm2_precision_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "coef = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for c in coef:\n",
    "    lr_norm2 = linear_model.LogisticRegression(C = c)\n",
    "    lr_norm2.fit(train_NMF_2, train_targets)\n",
    "    lr_norm2_predicted = lr_norm2.predict(test_NMF)\n",
    "    y_score_test_lr_norm2 = lr_norm2.decision_function(test_NMF)\n",
    "    print (\"coef:\", c)\n",
    "    print (confusion_matrix(test_targets, lr_norm2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part h i - L1 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for  L-2  ###\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "lr_norm1 = linear_model.LogisticRegression(penalty = 'l1')\n",
    "lr_norm1.fit(train_LSI_2, train_targets)\n",
    "\n",
    "y_score_test_lr_norm1 = lr_norm1.decision_function(test_LSI)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_norm1_predicted = lr_norm1.predict(test_LSI)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm1_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_norm1_predicted = lr_norm1.predict(test_LSI)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm1_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for  L-5  ###\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "lr_norm1 = linear_model.LogisticRegression(penalty = 'l1')\n",
    "lr_norm1.fit(train_LSI_5, train_targets)\n",
    "\n",
    "y_score_test_lr_norm1 = lr_norm1.decision_function(test_LSI)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "lr_norm1_predicted = lr_norm1.predict(test_LSI)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm1_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_norm1_accuracy = accuracy_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "lr_norm1_recall_score = recall_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "lr_norm1_precision_score = precision_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_precision_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "coef = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for c in coef:\n",
    "    lr_norm1 = linear_model.LogisticRegression(C = c)\n",
    "    lr_norm1.fit(train_LSI_5, train_targets)\n",
    "    lr_norm1_predicted = lr_norm1.predict(test_LSI)\n",
    "    y_score_test_lr_norm1 = lr_norm1.decision_function(test_LSI)\n",
    "    print (\"coef:\", c)\n",
    "    print (confusion_matrix(test_targets, lr_norm1_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for NMF ###\n",
    "from sklearn import linear_model, datasets\n",
    "lr_norm1 = linear_model.LogisticRegression(penalty = 'l1')\n",
    "lr_norm1.fit(train_NMF_2, train_targets)\n",
    "\n",
    "y_score_test_lr_norm1 = lr_norm1.decision_function(test_NMF)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_targets, y_score_test_lr_norm1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "lr_norm1_predicted = lr_norm1.predict(test_NMF)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_targets, lr_norm1_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_norm1_accuracy = accuracy_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_accuracy)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "lr_norm1_recall_score = recall_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_recall_score)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "lr_norm1_precision_score = precision_score(test_targets, lr_norm1_predicted)\n",
    "print (lr_norm1_precision_score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "coef = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for c in coef:\n",
    "    lr_norm1 = linear_model.LogisticRegression(C = c)\n",
    "    lr_norm1.fit(train_NMF_2, train_targets)\n",
    "    lr_norm1_predicted = lr_norm1.predict(test_NMF)\n",
    "    y_score_test_lr_norm1 = lr_norm1.decision_function(test_NMF)\n",
    "    print (\"coef:\", c)\n",
    "    print (confusion_matrix(test_targets, lr_norm1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "test = fetch_20newsgroups(subset=\"test\", categories=categories, shuffle=True, random_state=42)\n",
    "train_idf_2 = pipeline_2.fit_transform(train.data)\n",
    "Y_2 = NMF(n_components=50)\n",
    "train_NMF_2 = Y_2.fit_transform(train_idf_2)\n",
    "\n",
    "test_idf_2 = pipeline_2.transform(test.data)\n",
    "test_NMF = Y_2.transform(test_idf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import itertools\n",
    "class_names = ['pc_hardware', 'mac_hardware', 'misc_forsale', 'religion_christian']\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "    print (cm.shape)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"%.2f\"%cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Multiclass NB - NMF ##########\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB().fit(train_NMF_2, train.target)\n",
    "\n",
    "nb_predicted = nb_clf.predict(test_NMF)\n",
    "\n",
    "nb_accuracy = accuracy_score(test.target, nb_predicted)\n",
    "print \"NB accuracy: \", nb_accuracy\n",
    "nb_recall_score = recall_score(test.target, nb_predicted, average='weighted')\n",
    "print \"NB recall: \", nb_recall_score\n",
    "nb_precision_score = precision_score(test.target, nb_predicted, average='weighted')\n",
    "print \"NB precision: \", nb_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test.target, nb_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Multiclass SVM - One Vs One - NMF##########\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ovo_svc = OneVsOneClassifier(LinearSVC(C=100, random_state=42)).fit(train_NMF_2, train.target)\n",
    "ovo_predicted = ovo_svc.predict(test_NMF)\n",
    "\n",
    "ovo_predicted_predicted_accuracy = accuracy_score(test.target, ovo_predicted)\n",
    "print \"One Vs One SVM accuracy: \", ovo_predicted_predicted_accuracy\n",
    "\n",
    "ovo_predicted_recall_score = recall_score(test.target, ovo_predicted,average='weighted')\n",
    "print \"One Vs One SVM recall: \", ovo_predicted_recall_score\n",
    "\n",
    "ovo_predicted_precision_score = precision_score(test.target, ovo_predicted,average='weighted')\n",
    "print \"One Vs One SVM precision: \", ovo_predicted_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test.target, ovo_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Multiclass SVM - One Vs Rest - NMF ##########\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_svc = OneVsRestClassifier(LinearSVC(C=100, random_state=42)).fit(train_NMF_2, train.target)\n",
    "ovr_predicted = ovr_svc.predict(test_NMF)\n",
    "\n",
    "ovr_predicted_predicted_accuracy = accuracy_score(test.target, ovr_predicted)\n",
    "print \"One Vs Rest SVM accuracy: \", ovr_predicted_predicted_accuracy\n",
    "\n",
    "ovr_predicted_recall_score = recall_score(test.target, ovr_predicted,average='weighted')\n",
    "print \"One Vs Rest SVM recall: \", ovr_predicted_recall_score\n",
    "\n",
    "ovr_predicted_precision_score = precision_score(test.target, ovr_predicted,average='weighted')\n",
    "print \"One Vs Rest SVM precision: \", ovr_predicted_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test.target, ovr_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Multiclass SVM - One Vs One - LSI ##########\n",
    "X_2 = TruncatedSVD(n_components=50)\n",
    "train_LSI_2 = X_2.fit_transform(train_idf_2)\n",
    "test_LSI = X_2.transform(test_idf_2)\n",
    "\n",
    "ovo_svc = OneVsOneClassifier(LinearSVC(C=100, random_state=42)).fit(train_LSI_2, train.target)\n",
    "ovo_predicted = ovo_svc.predict(test_LSI)\n",
    "\n",
    "ovo_predicted_predicted_accuracy = accuracy_score(test.target, ovo_predicted)\n",
    "print \"One Vs One SVM accuracy: \", ovo_predicted_predicted_accuracy\n",
    "\n",
    "ovo_predicted_recall_score = recall_score(test.target, ovo_predicted,average='weighted')\n",
    "print \"One Vs One SVM recall: \", ovo_predicted_recall_score\n",
    "\n",
    "ovo_predicted_precision_score = precision_score(test.target, ovo_predicted,average='weighted')\n",
    "print \"One Vs One SVM precision: \", ovo_predicted_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test.target, ovo_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## Multiclass SVM - One Vs Rest - LSI ##########\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_svc = OneVsRestClassifier(LinearSVC(C=100, random_state=42)).fit(train_LSI_2, train.target)\n",
    "ovr_predicted = ovr_svc.predict(test_LSI)\n",
    "\n",
    "ovr_predicted_predicted_accuracy = accuracy_score(test.target, ovr_predicted)\n",
    "print \"One Vs Rest SVM accuracy: \", ovr_predicted_predicted_accuracy\n",
    "\n",
    "ovr_predicted_recall_score = recall_score(test.target, ovr_predicted,average='weighted')\n",
    "print \"One Vs Rest SVM recall: \", ovr_predicted_recall_score\n",
    "\n",
    "ovr_predicted_precision_score = precision_score(test.target, ovr_predicted,average='weighted')\n",
    "print \"One Vs Rest SVM precision: \", ovr_predicted_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test.target, ovo_predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
